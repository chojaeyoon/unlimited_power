{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"LSTM_mk3.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm","mount_file_id":"1KvPuJzzKBIetEhzRCFkKxUv-mxtjR3V8","authorship_tag":"ABX9TyMYu9H3nJ/+aZoNgVnXe91B"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"TPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"gH7tceTn_JfT"},"source":["점점 미쳐가는 중\r\n","\r\n","###사유\r\n","\r\n","7일의 데이터를 사용해서 2일의 데이터를 예측해야한다ㅏㅏㅏㅏㅏㅏㅏㅏㅏㅏㅏ\r\n","\r\n","\r\n","###문제\r\n","\r\n","많은 것이 문제, 무엇보다 문제는 **input과 output의 모양이 달라서** 도통 되먹지를 않는다.\r\n","\r\n","일단 7일치를 2일치로 퉁치는 것이 문제임\r\n","\r\n","두 번째 문제는 변수 6개로 1개 예측하는 것이 문제임\r\n","\r\n","합치면, **7일치의 변수 6개로, 2일치 정답변수 1개를 예측하는 문제**가 되어서 난장판ㄴㄴㄴㄴㄴ\r\n","\r\n","문제2, 원래 LSTM은 이미지 처리, 텍스트 처리에 쓰는 경우가 많아서 일단 이런 회귀는 다른 모델이 더 좋다. 애초에 들어가서 구동이 안됨\r\n","\r\n","\r\n","### 방안\r\n","\r\n","자연어(NLP) 해석 신경망을 훔쳐왔다.\r\n","\r\n","**한국어 - 영어 해석은 input과 output shape(글자의 숫자, 주어/동사/목적어)이 달라도 돌아간다.**\r\n","\r\n","그런고로 7일치 6개의 변수 > 2일치 1개의 정답도 대충 되지 않을까 기대함.\r\n","\r\n","안되면 환불손절"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4QgGhECmF2Rl","executionInfo":{"status":"ok","timestamp":1609095180455,"user_tz":-540,"elapsed":3037,"user":{"displayName":"‍최명진(학부학생/사회과학대학 사회복지학과)","photoUrl":"","userId":"07688453603143010105"}},"outputId":"ae6b7183-2ce9-45d5-812c-7e997dba385b"},"source":["from google.colab import drive\r\n","!pip install import_ipynb\r\n","import import_ipynb\r\n","# 구글 드라이브에 자료 전처리 함수, raw_data 올려놓았다.\r\n","# 일단 불러오기\r\n","drive.mount('/content/drive')"],"execution_count":6,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: import_ipynb in /usr/local/lib/python3.6/dist-packages (0.1.3)\n","Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"bNzfUuVt-uFM","executionInfo":{"status":"ok","timestamp":1609095180456,"user_tz":-540,"elapsed":3034,"user":{"displayName":"‍최명진(학부학생/사회과학대학 사회복지학과)","photoUrl":"","userId":"07688453603143010105"}}},"source":["import pandas as pd\r\n","from pandas import Series, DataFrame\r\n","from matplotlib import pyplot\r\n","import matplotlib.pyplot as plt\r\n","from sklearn.preprocessing import MinMaxScaler\r\n","import numpy as np\r\n","import seaborn as sns\r\n","from pandas import DataFrame\r\n","from pandas import concat\r\n","import os\r\n","from sklearn.model_selection import train_test_split\r\n","import torch\r\n","import torch.nn as nn\r\n","from torch.utils.data import TensorDataset, DataLoader\r\n","import torch.optim as optim"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"7wZeTugBGKf5","executionInfo":{"status":"ok","timestamp":1609095180456,"user_tz":-540,"elapsed":3031,"user":{"displayName":"‍최명진(학부학생/사회과학대학 사회복지학과)","photoUrl":"","userId":"07688453603143010105"}}},"source":["raw_data = pd.read_csv('/content/drive/MyDrive/Jupyter/unlimited_power/raw_data/train/train.csv')"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"6BJ8W7-qGgrg","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1609095185357,"user_tz":-540,"elapsed":7929,"user":{"displayName":"‍최명진(학부학생/사회과학대학 사회복지학과)","photoUrl":"","userId":"07688453603143010105"}},"outputId":"7472e7c0-57f1-443c-ff13-7219a0a16e7d"},"source":["# !cp가 뭔지는 모르지만, 이렇게 해야 함수를 불러올 수 있다고 함.\r\n","# lstm_defs.py에 전처리 함수를 저장해 놓았으므로 얘를 MJ로 불러온다.\r\n","!cp /content/drive/MyDrive/Jupyter/unlimited_power/working__/LSTM_functions.ipynb .\r\n","import LSTM_functions as MJ\r\n","\r\n","# 불러온 데이터를 MJ.py에 미리 정의해 둔 data_loadder 함수에 때려 넣으면\r\n","# 자동으로 train_X, train_y, test_X, test_y 4가지가 선언된다.\r\n","train_set, test_set = MJ.preprocessing(raw_data)"],"execution_count":9,"outputs":[{"output_type":"stream","text":["Final Shape is :\n","torch.Size([100, 336, 6])\n","torch.Size([100, 96])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ihdw4nZfO9UA","executionInfo":{"status":"ok","timestamp":1609095185358,"user_tz":-540,"elapsed":7927,"user":{"displayName":"‍최명진(학부학생/사회과학대학 사회복지학과)","photoUrl":"","userId":"07688453603143010105"}}},"source":["### parameters\r\n","\r\n","## 학습에 사용할 변수의 개수 5개 + target 변수(7일간)\r\n","n_features = 6"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"aHSufBeM-0Zy","executionInfo":{"status":"ok","timestamp":1609095185358,"user_tz":-540,"elapsed":7925,"user":{"displayName":"‍최명진(학부학생/사회과학대학 사회복지학과)","photoUrl":"","userId":"07688453603143010105"}}},"source":["class Encoder(nn.Module):\r\n","\r\n","    def __init__(self, input_size, hidden_dim, num_layers=3):\r\n","        super(Encoder, self).__init__()\r\n","\r\n","        self.input_size = input_size\r\n","        self.hidden_dim = hidden_dim\r\n","        self.num_layers = num_layers\r\n","        self.lstm = nn.LSTM(self.input_size, self.hidden_dim, num_layers=self.num_layers)\r\n","        self.hidden = None\r\n","\r\n","    def init_hidden(self, batch_size):\r\n","        return (torch.zeros(self.num_layers, batch_size, self.hidden_dim),\r\n","                torch.zeros(self.num_layers, batch_size, self.hidden_dim))\r\n","\r\n","    def forward(self, inputs):\r\n","        # Push through RNN layer (the ouput is irrelevant)\r\n","        _, self.hidden = self.lstm(inputs, self.hidden)\r\n","        return self.hidden"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"hFS4Dkbn-4zb","executionInfo":{"status":"ok","timestamp":1609095185359,"user_tz":-540,"elapsed":7923,"user":{"displayName":"‍최명진(학부학생/사회과학대학 사회복지학과)","photoUrl":"","userId":"07688453603143010105"}}},"source":["class Decoder(nn.Module):\r\n","\r\n","    def __init__(self, hidden_dim, num_layers=3):\r\n","        super(Decoder, self).__init__()\r\n","        # input_size=1 since the output are single values\r\n","        self.lstm = nn.LSTM(1, hidden_dim, num_layers=num_layers)\r\n","        self.out = nn.Linear(hidden_dim, 1)\r\n","\r\n","    def forward(self, outputs, hidden): #, criterion):\r\n","        batch_size, num_steps = outputs.shape\r\n","        # Create initial start value/token\r\n","        input = torch.tensor([[0.0]] * batch_size, dtype=torch.float)\r\n","        # Convert (batch_size, output_size) to (seq_len, batch_size, output_size)\r\n","        input = input.unsqueeze(0)\r\n","\r\n","        loss = 0\r\n","        for i in range(num_steps):\r\n","            # Push current input through LSTM: (seq_len=1, batch_size, input_size=1)\r\n","            output, hidden = self.lstm(input, hidden)\r\n","            # Push the output of last step through linear layer; returns (batch_size, 1)\r\n","            output = self.out(output[-1])\r\n","            # Generate input for next step by adding seq_len dimension (see above)\r\n","            input = output.unsqueeze(0)\r\n","            # Compute loss between predicted value and true value\r\n","            loss += tilted_loss(0.5, output, outputs[:, i])\r\n","        return loss"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"H6npq-BaPbcH","executionInfo":{"status":"ok","timestamp":1609095185359,"user_tz":-540,"elapsed":7921,"user":{"displayName":"‍최명진(학부학생/사회과학대학 사회복지학과)","photoUrl":"","userId":"07688453603143010105"}}},"source":["# 손실함수\r\n","# Quantile 별로 구해야하니까, q 값에 quantile을 넣어야한다.\r\n","\r\n","def tilted_loss(q,y,f):\r\n","    e = (y-f)\r\n","    return torch.mean(torch.max(q*e, (q-1)*e), axis=-1)"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"RKVZ_exOAYI2"},"source":["# if __name__ == '__main__':\r\n","\r\n","\r\n","#     # 5 is the number of features of your data points\r\n","#     encoder = Encoder(n_features, 64)\r\n","#     decoder = Decoder(64)\r\n","#     # Create optimizers for encoder and decoder\r\n","#     encoder_optimizer = optim.Adam(encoder.parameters(), lr=0.001)\r\n","#     decoder_optimizer = optim.Adam(decoder.parameters(), lr=0.001)\r\n","#     #criterion = nn.MSELoss()\r\n","\r\n","    \r\n","#     # Convert (batch_size, seq_len, input_size) to (seq_len, batch_size, input_size)\r\n","#     inputs = train_X\r\n","\r\n","#     # 2 sequences (to match the batch size) of length 6 (for the 6h into the future)\r\n","#     outputs = train_y\r\n","\r\n","#     # Do one complete forward & backward pass\r\n","#     #\r\n","#     # Zero gradients of both optimizers\r\n","#     encoder_optimizer.zero_grad()\r\n","#     decoder_optimizer.zero_grad()\r\n","#     # Reset hidden state of encoder for current batch\r\n","#     encoder.hidden = encoder.init_hidden(inputs.shape[1])\r\n","#     # Do forward pass through encoder\r\n","#     hidden = encoder(inputs)\r\n","#     # Do forward pass through decoder (decoder gets hidden state from encoder)\r\n","#     loss = decoder(outputs, hidden)\r\n","#     # Backpropagation\r\n","#     loss.backward()\r\n","#     # Update parameters\r\n","#     encoder_optimizer.step()\r\n","#     decoder_optimizer.step()\r\n","#     print(\"Loss:\", loss.item())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"6RQgdkHpipto","executionInfo":{"status":"error","timestamp":1609095702231,"user_tz":-540,"elapsed":261701,"user":{"displayName":"‍최명진(학부학생/사회과학대학 사회복지학과)","photoUrl":"","userId":"07688453603143010105"}},"outputId":"e6125d88-8631-4e65-de06-7645d1aa2c46"},"source":["epoch = 2\r\n","\r\n","for i in range(epoch):\r\n","    for i, (train, train_target) in enumerate(train_set):\r\n","          # 5 is the number of features of your data points\r\n","      \r\n","      encoder = Encoder(n_features, 64)\r\n","      decoder = Decoder(64)\r\n","      # Create optimizers for encoder and decoder\r\n","      encoder_optimizer = optim.Adam(encoder.parameters(), lr=0.001)\r\n","      decoder_optimizer = optim.Adam(decoder.parameters(), lr=0.001)\r\n","      #criterion = nn.MSELoss()\r\n","\r\n","      \r\n","      # Convert (batch_size, seq_len, input_size) to (seq_len, batch_size, input_size)\r\n","      inputs = train\r\n","      inputs = inputs.transpose(1,0) .float()\r\n","\r\n","      # 2 sequences (to match the batch size) of length 6 (for the 6h into the future)\r\n","      outputs = train_target\r\n","\r\n","      # Do one complete forward & backward pass\r\n","      #\r\n","      # Zero gradients of both optimizers\r\n","      encoder_optimizer.zero_grad()\r\n","      decoder_optimizer.zero_grad()\r\n","      # Reset hidden state of encoder for current batch\r\n","      encoder.hidden = encoder.init_hidden(inputs.shape[1])\r\n","      # Do forward pass through encoder\r\n","      hidden = encoder(inputs)\r\n","      # Do forward pass through decoder (decoder gets hidden state from encoder)\r\n","      loss = decoder(outputs, hidden)\r\n","      # Backpropagation\r\n","      loss.sum().backward()\r\n","      # Update parameters\r\n","      encoder_optimizer.step()\r\n","      decoder_optimizer.step()\r\n","      print(\"Loss:\", loss.sum())"],"execution_count":20,"outputs":[{"output_type":"stream","text":["Loss: tensor(88930.5714, dtype=torch.float64, grad_fn=<SumBackward0>)\n","Loss: tensor(83151.8809, dtype=torch.float64, grad_fn=<SumBackward0>)\n","Loss: tensor(83331.5392, dtype=torch.float64, grad_fn=<SumBackward0>)\n","Loss: tensor(89166.3485, dtype=torch.float64, grad_fn=<SumBackward0>)\n","Loss: tensor(85740.1672, dtype=torch.float64, grad_fn=<SumBackward0>)\n","Loss: tensor(82546.4352, dtype=torch.float64, grad_fn=<SumBackward0>)\n","Loss: tensor(87338.0634, dtype=torch.float64, grad_fn=<SumBackward0>)\n","Loss: tensor(83028.5089, dtype=torch.float64, grad_fn=<SumBackward0>)\n","Loss: tensor(89291.1277, dtype=torch.float64, grad_fn=<SumBackward0>)\n","Loss: tensor(84007.8930, dtype=torch.float64, grad_fn=<SumBackward0>)\n","Loss: tensor(81458.4588, dtype=torch.float64, grad_fn=<SumBackward0>)\n","Loss: tensor(86581.7311, dtype=torch.float64, grad_fn=<SumBackward0>)\n","Loss: tensor(86634.8807, dtype=torch.float64, grad_fn=<SumBackward0>)\n","Loss: tensor(88242.8439, dtype=torch.float64, grad_fn=<SumBackward0>)\n","Loss: tensor(85543.7845, dtype=torch.float64, grad_fn=<SumBackward0>)\n","Loss: tensor(85688.9018, dtype=torch.float64, grad_fn=<SumBackward0>)\n","Loss: tensor(82679.0459, dtype=torch.float64, grad_fn=<SumBackward0>)\n","Loss: tensor(88087.4594, dtype=torch.float64, grad_fn=<SumBackward0>)\n","Loss: tensor(88880.9249, dtype=torch.float64, grad_fn=<SumBackward0>)\n","Loss: tensor(90017.2707, dtype=torch.float64, grad_fn=<SumBackward0>)\n","Loss: tensor(82215.9331, dtype=torch.float64, grad_fn=<SumBackward0>)\n","Loss: tensor(84611.6536, dtype=torch.float64, grad_fn=<SumBackward0>)\n","Loss: tensor(83587.6754, dtype=torch.float64, grad_fn=<SumBackward0>)\n","Loss: tensor(85170.7756, dtype=torch.float64, grad_fn=<SumBackward0>)\n","Loss: tensor(83179.6031, dtype=torch.float64, grad_fn=<SumBackward0>)\n","Loss: tensor(84403.2596, dtype=torch.float64, grad_fn=<SumBackward0>)\n","Loss: tensor(87366.0917, dtype=torch.float64, grad_fn=<SumBackward0>)\n","Loss: tensor(88792.6882, dtype=torch.float64, grad_fn=<SumBackward0>)\n","Loss: tensor(87198.0613, dtype=torch.float64, grad_fn=<SumBackward0>)\n","Loss: tensor(89572.2715, dtype=torch.float64, grad_fn=<SumBackward0>)\n","Loss: tensor(84066.2083, dtype=torch.float64, grad_fn=<SumBackward0>)\n","Loss: tensor(78032.4489, dtype=torch.float64, grad_fn=<SumBackward0>)\n","Loss: tensor(84688.7295, dtype=torch.float64, grad_fn=<SumBackward0>)\n","Loss: tensor(87685.9601, dtype=torch.float64, grad_fn=<SumBackward0>)\n","Loss: tensor(90621.7322, dtype=torch.float64, grad_fn=<SumBackward0>)\n","Loss: tensor(86737.3094, dtype=torch.float64, grad_fn=<SumBackward0>)\n","Loss: tensor(84565.8386, dtype=torch.float64, grad_fn=<SumBackward0>)\n","Loss: tensor(90755.4127, dtype=torch.float64, grad_fn=<SumBackward0>)\n","Loss: tensor(87773.2833, dtype=torch.float64, grad_fn=<SumBackward0>)\n","Loss: tensor(86672.5546, dtype=torch.float64, grad_fn=<SumBackward0>)\n","Loss: tensor(87171.1196, dtype=torch.float64, grad_fn=<SumBackward0>)\n","Loss: tensor(86000.3768, dtype=torch.float64, grad_fn=<SumBackward0>)\n","Loss: tensor(87731.2585, dtype=torch.float64, grad_fn=<SumBackward0>)\n","Loss: tensor(90133.0702, dtype=torch.float64, grad_fn=<SumBackward0>)\n","Loss: tensor(89685.3003, dtype=torch.float64, grad_fn=<SumBackward0>)\n","Loss: tensor(88355.3210, dtype=torch.float64, grad_fn=<SumBackward0>)\n","Loss: tensor(87275.6312, dtype=torch.float64, grad_fn=<SumBackward0>)\n","Loss: tensor(84547.8547, dtype=torch.float64, grad_fn=<SumBackward0>)\n","Loss: tensor(89985.7233, dtype=torch.float64, grad_fn=<SumBackward0>)\n","Loss: tensor(88649.6405, dtype=torch.float64, grad_fn=<SumBackward0>)\n","Loss: tensor(82115.1401, dtype=torch.float64, grad_fn=<SumBackward0>)\n","Loss: tensor(88892.9315, dtype=torch.float64, grad_fn=<SumBackward0>)\n","Loss: tensor(86166.0673, dtype=torch.float64, grad_fn=<SumBackward0>)\n","Loss: tensor(92359.7752, dtype=torch.float64, grad_fn=<SumBackward0>)\n","Loss: tensor(97228.0647, dtype=torch.float64, grad_fn=<SumBackward0>)\n","Loss: tensor(84477.5918, dtype=torch.float64, grad_fn=<SumBackward0>)\n","Loss: tensor(93099.1110, dtype=torch.float64, grad_fn=<SumBackward0>)\n","Loss: tensor(77632.2137, dtype=torch.float64, grad_fn=<SumBackward0>)\n","Loss: tensor(87640.9504, dtype=torch.float64, grad_fn=<SumBackward0>)\n","Loss: tensor(84561.5158, dtype=torch.float64, grad_fn=<SumBackward0>)\n","Loss: tensor(85950.6723, dtype=torch.float64, grad_fn=<SumBackward0>)\n","Loss: tensor(88138.8848, dtype=torch.float64, grad_fn=<SumBackward0>)\n","Loss: tensor(85778.7189, dtype=torch.float64, grad_fn=<SumBackward0>)\n","Loss: tensor(83945.1183, dtype=torch.float64, grad_fn=<SumBackward0>)\n","Loss: tensor(85465.5258, dtype=torch.float64, grad_fn=<SumBackward0>)\n","Loss: tensor(88601.7778, dtype=torch.float64, grad_fn=<SumBackward0>)\n","Loss: tensor(88302.8396, dtype=torch.float64, grad_fn=<SumBackward0>)\n","Loss: tensor(79124.2736, dtype=torch.float64, grad_fn=<SumBackward0>)\n","Loss: tensor(89003.8037, dtype=torch.float64, grad_fn=<SumBackward0>)\n","Loss: tensor(82582.2281, dtype=torch.float64, grad_fn=<SumBackward0>)\n","Loss: tensor(87983.2232, dtype=torch.float64, grad_fn=<SumBackward0>)\n","Loss: tensor(79324.8749, dtype=torch.float64, grad_fn=<SumBackward0>)\n","Loss: tensor(94265.8045, dtype=torch.float64, grad_fn=<SumBackward0>)\n","Loss: tensor(82420.3143, dtype=torch.float64, grad_fn=<SumBackward0>)\n","Loss: tensor(84502.2228, dtype=torch.float64, grad_fn=<SumBackward0>)\n","Loss: tensor(85698.1744, dtype=torch.float64, grad_fn=<SumBackward0>)\n","Loss: tensor(83628.9743, dtype=torch.float64, grad_fn=<SumBackward0>)\n","Loss: tensor(82160.6838, dtype=torch.float64, grad_fn=<SumBackward0>)\n","Loss: tensor(84238.1518, dtype=torch.float64, grad_fn=<SumBackward0>)\n","Loss: tensor(86418.6031, dtype=torch.float64, grad_fn=<SumBackward0>)\n","Loss: tensor(86537.1001, dtype=torch.float64, grad_fn=<SumBackward0>)\n","Loss: tensor(87687.4096, dtype=torch.float64, grad_fn=<SumBackward0>)\n","Loss: tensor(80854.9277, dtype=torch.float64, grad_fn=<SumBackward0>)\n","Loss: tensor(80997.6504, dtype=torch.float64, grad_fn=<SumBackward0>)\n","Loss: tensor(82799.1317, dtype=torch.float64, grad_fn=<SumBackward0>)\n","Loss: tensor(89021.5508, dtype=torch.float64, grad_fn=<SumBackward0>)\n","Loss: tensor(86604.8588, dtype=torch.float64, grad_fn=<SumBackward0>)\n","Loss: tensor(87891.8098, dtype=torch.float64, grad_fn=<SumBackward0>)\n","Loss: tensor(83286.1129, dtype=torch.float64, grad_fn=<SumBackward0>)\n","Loss: tensor(83894.4566, dtype=torch.float64, grad_fn=<SumBackward0>)\n","Loss: tensor(87271.9468, dtype=torch.float64, grad_fn=<SumBackward0>)\n","Loss: tensor(88461.8307, dtype=torch.float64, grad_fn=<SumBackward0>)\n","Loss: tensor(80746.4902, dtype=torch.float64, grad_fn=<SumBackward0>)\n","Loss: tensor(80216.7418, dtype=torch.float64, grad_fn=<SumBackward0>)\n","Loss: tensor(82100.5185, dtype=torch.float64, grad_fn=<SumBackward0>)\n","Loss: tensor(82923.1793, dtype=torch.float64, grad_fn=<SumBackward0>)\n","Loss: tensor(87882.1775, dtype=torch.float64, grad_fn=<SumBackward0>)\n","Loss: tensor(86847.4645, dtype=torch.float64, grad_fn=<SumBackward0>)\n","Loss: tensor(86031.2135, dtype=torch.float64, grad_fn=<SumBackward0>)\n","Loss: tensor(83308.6003, dtype=torch.float64, grad_fn=<SumBackward0>)\n","Loss: tensor(85230.0202, dtype=torch.float64, grad_fn=<SumBackward0>)\n","Loss: tensor(79254.7286, dtype=torch.float64, grad_fn=<SumBackward0>)\n","Loss: tensor(83779.4064, dtype=torch.float64, grad_fn=<SumBackward0>)\n","Loss: tensor(87837.4229, dtype=torch.float64, grad_fn=<SumBackward0>)\n","Loss: tensor(84863.4521, dtype=torch.float64, grad_fn=<SumBackward0>)\n","Loss: tensor(84286.3903, dtype=torch.float64, grad_fn=<SumBackward0>)\n","Loss: tensor(84485.0825, dtype=torch.float64, grad_fn=<SumBackward0>)\n","Loss: tensor(89661.4874, dtype=torch.float64, grad_fn=<SumBackward0>)\n","Loss: tensor(83005.0466, dtype=torch.float64, grad_fn=<SumBackward0>)\n","Loss: tensor(94068.7743, dtype=torch.float64, grad_fn=<SumBackward0>)\n","Loss: tensor(86391.7728, dtype=torch.float64, grad_fn=<SumBackward0>)\n","Loss: tensor(90157.9008, dtype=torch.float64, grad_fn=<SumBackward0>)\n"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-20-7483418b8878>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m       \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m       \u001b[0;31m# Backpropagation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m       \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m       \u001b[0;31m# Update parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m       \u001b[0mencoder_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m                 create_graph=create_graph)\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    130\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    131\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]}]}