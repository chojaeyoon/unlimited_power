{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"LSTM_mk2.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMDmqqJHu75eU5ViElt5WYI"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"qtWZ3hraAxci"},"source":["### 본격적으로 연습한 코드를 세련되게 다듬어 보는 중\r\n","\r\n","Input > Output이 너무 달라서 욕함\r\n","\r\n","보통의 경우 / 하나의 변수(시계열), n 일간의 데이터 학습 > 1개의 정답\r\n","\r\n","이번 경우 / 일단 변수가 5~6개, 거기에 n일 + 정답이 1개가 아님, 2일치로 쭉 뽑아내야 함"]},{"cell_type":"code","metadata":{"id":"scq1NVZ-Bf2l","executionInfo":{"status":"ok","timestamp":1609093907464,"user_tz":-540,"elapsed":787,"user":{"displayName":"‍최명진(학부학생/사회과학대학 사회복지학과)","photoUrl":"","userId":"07688453603143010105"}}},"source":["import pandas as pd\r\n","from google.colab import drive\r\n","from pandas import Series, DataFrame\r\n","from matplotlib import pyplot\r\n","import matplotlib.pyplot as plt\r\n","from sklearn.preprocessing import MinMaxScaler\r\n","import numpy as np\r\n","import seaborn as sns\r\n","from pandas import DataFrame\r\n","from pandas import concat\r\n","import os\r\n","from sklearn.model_selection import train_test_split\r\n","import torch\r\n","import torch.nn as nn\r\n","from torch.utils.data import TensorDataset, DataLoader\r\n","import torch.optim as optim"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DTuTqMD1Biui","executionInfo":{"status":"ok","timestamp":1609093907464,"user_tz":-540,"elapsed":783,"user":{"displayName":"‍최명진(학부학생/사회과학대학 사회복지학과)","photoUrl":"","userId":"07688453603143010105"}},"outputId":"6031cd5c-b838-4599-cab0-ebc57a5fdad3"},"source":["drive.mount('/content/drive')"],"execution_count":12,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"C5PEHrCOCExR","executionInfo":{"status":"ok","timestamp":1609093907464,"user_tz":-540,"elapsed":779,"user":{"displayName":"‍최명진(학부학생/사회과학대학 사회복지학과)","photoUrl":"","userId":"07688453603143010105"}}},"source":["raw_data = pd.read_csv('/content/drive/MyDrive/Jupyter/unlimited_power/raw_data/train/train.csv')"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"IsKoGn6fDqe2","executionInfo":{"status":"ok","timestamp":1609093907465,"user_tz":-540,"elapsed":777,"user":{"displayName":"‍최명진(학부학생/사회과학대학 사회복지학과)","photoUrl":"","userId":"07688453603143010105"}}},"source":["def drop_clms(dataset):\r\n","  dataset['Time'] = dataset['Hour'] + dataset['Minute']*(0.5/30)\r\n","  dataset = dataset[what_to_use]\r\n","  return dataset"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"5vbSb9AuEbPT","executionInfo":{"status":"ok","timestamp":1609093907734,"user_tz":-540,"elapsed":1043,"user":{"displayName":"‍최명진(학부학생/사회과학대학 사회복지학과)","photoUrl":"","userId":"07688453603143010105"}}},"source":["# 머신러닝에 쓰기 위해서 재정렬 시키는 함수\r\n","def series_to_supervised(data, n_in=1, n_out=1, target = 'TARGET', dropnan=True):\r\n","    df = DataFrame(data)\r\n","    df.drop(target, axis = 1, inplace=True)\r\n","    df2 = DataFrame(data[target])\r\n","    cols, names = list(), list()\r\n","    n_vars = 1 if type(df) is list else df.shape[1]\r\n","    n_vars2 = 1 if type(df2) is list else df2.shape[1]\r\n","    # input sequence (t-n, ... t-1)\r\n","    for i in range(n_in, 0, -1):\r\n","        cols.append(df.shift(i))\r\n","        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\r\n","    # forecast sequence (t, t+1, ... t+n)\r\n","    for i in range(0, n_out):\r\n","        cols.append(df2.shift(-i))\r\n","        if i == 0:\r\n","            names += [('TARGET%d(t)' % (j+1)) for j in range(n_vars2)]\r\n","        else:\r\n","            names += [('TARGET%d(t+%d)' % (j+1, i)) for j in range(n_vars2)]\r\n","    # put it all together\r\n","    agg = concat(cols, axis=1)\r\n","    agg.columns = names\r\n","    # drop rows with NaN values\r\n","    if dropnan:\r\n","        agg.dropna(inplace=True)\r\n","    return agg"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ekcv5mKEFBDa","executionInfo":{"status":"ok","timestamp":1609093907735,"user_tz":-540,"elapsed":1042,"user":{"displayName":"‍최명진(학부학생/사회과학대학 사회복지학과)","photoUrl":"","userId":"07688453603143010105"}}},"source":["def seperator(dataset):\r\n","  \r\n","  # series_to_supervised 함수를 지나며 전처리를 하면 하나의 row에 이전 7일간의 데이터가 일렬로 들어가고(train), 여기에 target으로 미래 96일 발전량이 따라 붙는다.\r\n","  # 이 둘이 한 줄에 있으므로 적절한 지점에서 잘라서 train_X와 train_y로 사용한다.\r\n","  X = dataset.iloc[:, :n_obs]\r\n","  y = dataset.iloc[:, -future_window:]\r\n","  \r\n","  # validation을 해야하니까, train으로 준 데이터를 train/test로 자른다.\r\n","  # 사용가능한 연도가 3개년이고, 대충 train에 2년치, test에 1년치를 주었다 (7:3)\r\n","  # 42 = ultimate answer to life the universe and everything\r\n","  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)\r\n","\r\n","  # 학습과 검증 데이터를 원하는 모양([1,4,2]) 이런 식으로 바꾸는 함수\r\n","  #### 처음 모양 (36490, 2016)\r\n","  # 2년치가 데이터(730일 * 하루에 48틱 = 36490개)로 있고, 이전 일주일 데이터 7*48 = 336인데 사용한 변수가 6개라면 336*6이다.\r\n","  # 일단 2016개의 데이터를 틱별로(30분 단위로) 잘라준다\r\n","  # 한 틱에 6개의 변수가 들어간다면 이를 n_features로 반영\r\n","  \r\n","  #### 수정할 모양 (36490, 336, 6)\r\n","  # 6개 특징이 30분 단위로 336개(일주일) 준비되어 있다.\r\n","  # 이런 데이터가 36490개 있어서 학습에 사용할 수 있다.\r\n","\r\n","  # y 데이터는 1개 변수(발전량)만 나오고, 미래 2일 (2*48 = 96틱)이므로\r\n","  # 형태 ('총 데이터의 개수', '미래/과거의 길이', '사용한 변수의 개수')\r\n","  # == (36490, 96, 1) 으로 reshape 한다.\r\n","\r\n","  train_X = X_train.values\r\n","  train_X = train_X.reshape(train_X.shape[0],-1,n_features)\r\n","  train_y = y_train.values\r\n","  train_y = train_y.reshape(train_y.shape[0],future_window)\r\n","\r\n","  test_X = X_test.values\r\n","  test_X = test_X.reshape(test_X.shape[0],-1,n_features)\r\n","  test_y = y_test.values\r\n","  test_y = test_y.reshape(test_y.shape[0],future_window)\r\n","\r\n","  return train_X, train_y, test_X, test_y"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZZP4mwn8Io_q","executionInfo":{"status":"ok","timestamp":1609093907735,"user_tz":-540,"elapsed":1040,"user":{"displayName":"‍최명진(학부학생/사회과학대학 사회복지학과)","photoUrl":"","userId":"07688453603143010105"}}},"source":["def data_maker(train_X, train_y, test_X, test_y):\r\n","  train_data = TensorDataset(torch.from_numpy(train_X), torch.from_numpy(train_y))\r\n","  val_data = TensorDataset(torch.from_numpy(test_X), torch.from_numpy(test_y))\r\n","  train_set = DataLoader(train_data, batch_size = batches, shuffle=True)\r\n","  test_set = DataLoader(val_data, batch_size = batches, shuffle=True)\r\n","  dateiter = iter(train_set)\r\n","  tx,ty = dateiter.next()\r\n","  print(\"Final Shape is :\")\r\n","  print(tx.size())\r\n","  print(ty.size())\r\n","  return train_set, test_set"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"id":"zFkNSVlqElEu","executionInfo":{"status":"ok","timestamp":1609093907735,"user_tz":-540,"elapsed":1037,"user":{"displayName":"‍최명진(학부학생/사회과학대학 사회복지학과)","photoUrl":"","userId":"07688453603143010105"}}},"source":["############ 파라미터 #####################\r\n","# 하루의 틱\r\n","ticks = 48\r\n","# 예측에 사용할 일수\r\n","days = 7\r\n","n_days = ticks*days\r\n","\r\n","# 미래 예측할 일수\r\n","future_days = 2\r\n","future_window = ticks * future_days\r\n","\r\n","### 모든변수\r\n","# ['Hour', 'Minute', 'Day', 'WS', 'Time', 'DHI','DNI','RH','T','TARGET']\r\n","# 사용할 변수\r\n","what_to_use = ['Time', 'DHI','DNI','RH','T','TARGET']\r\n","\r\n","n_features = len(what_to_use) - 1\r\n","n_obs = n_days * n_features\r\n","\r\n","# 한 번에 뭉테기로 투입할 자료의 양\r\n","batches = 100\r\n","# 몇 번이나 반복하여 학습할 것인다.\r\n","epoch = 200"],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"id":"oM66qsdJJT-4","executionInfo":{"status":"ok","timestamp":1609093907735,"user_tz":-540,"elapsed":1035,"user":{"displayName":"‍최명진(학부학생/사회과학대학 사회복지학과)","photoUrl":"","userId":"07688453603143010105"}}},"source":["def preprocessing(dataset):\r\n","  dataset = drop_clms(dataset)\r\n","  dataset = series_to_supervised(dataset, n_days, future_window, target='TARGET')\r\n","  train_X, train_y, test_X, test_y = seperator(dataset)\r\n","  train_set, test_set = data_maker(train_X, train_y, test_X, test_y)\r\n","  return train_set, test_set"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QV--SP8xKEzc","executionInfo":{"status":"ok","timestamp":1609093911906,"user_tz":-540,"elapsed":5202,"user":{"displayName":"‍최명진(학부학생/사회과학대학 사회복지학과)","photoUrl":"","userId":"07688453603143010105"}},"outputId":"f5949799-cef7-4006-8fbd-8f2d17b0271d"},"source":["train_set, test_set = preprocessing(raw_data)"],"execution_count":20,"outputs":[{"output_type":"stream","text":["Final Shape is :\n","torch.Size([100, 336, 5])\n","torch.Size([100, 96])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"NuSzX6WusDEU","executionInfo":{"status":"ok","timestamp":1609093900577,"user_tz":-540,"elapsed":650,"user":{"displayName":"‍최명진(학부학생/사회과학대학 사회복지학과)","photoUrl":"","userId":"07688453603143010105"}}},"source":["# 일단 변수는 5개, timestep은 336개(7일) 이므로, input_size는 5가 된다.\r\n","input_size = n_features\r\n","\r\n","# hidden_size는 input_size를 받아서 출력하는 크기를 나타낸다.\r\n","# 미래 2일, 96개를 출력해야 하므로 hidden_size = 96\r\n","hidden_size = future_window\r\n","\r\n","# Layer는 임의로 4개쯤 깔아준다.\r\n","layers = 4"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"6dnCPwPxKpOk"},"source":["## LSTM 함수 생성\r\n","\r\n","\r\n","class LSTM(nn.Module):\r\n","    \r\n","    # __init__은 class 즉, LSTM의 변수값을 정의하며 시작하는 역할을 한다.\r\n","    # self.input_size = 10이라고 하면, 이 함수의 input_size (=self의 input_size)를 10으로 정의하겠다는 의미\r\n","    \r\n","    def __init__(self,input_size, hidden_size):\r\n","        super().__init__()\r\n","        self.input_size = input_size\r\n","        self.hidden_size = hidden_size\r\n","        \r\n","        \r\n","        self.rnn = nn.LSTM(\r\n","            input_size = input_size, \r\n","            hidden_size = hidden_size, \r\n","            num_layers = layers, \r\n","            batch_first = True,\r\n","            bidirectional = True\r\n","        )\r\n","# Linear 뒤에가 출력값.\r\n","# bidirectional을 쓰기 때문에(역전파), 결과값 96개, 역전파 96개 즉 future_window의 두 배\r\n","        self.layers = nn.Sequential(\r\n","            nn.ReLU(),\r\n","            nn.Linear(hidden_size*2, hidden_size),\r\n","        )\r\n","        \r\n","    def forward(self, x):\r\n","        y,_ = self.rnn(x)\r\n","        y = self.layers(y)\r\n","        return y\r\n","    \r\n","model = LSTM(input_size, hidden_size)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hDAXLgz71Dhh","executionInfo":{"status":"ok","timestamp":1608995376067,"user_tz":-540,"elapsed":7881,"user":{"displayName":"‍최명진(학부학생/사회과학대학 사회복지학과)","photoUrl":"","userId":"07688453603143010105"}},"outputId":"c29ac6ec-7e7c-4aab-949b-af2df4eac810"},"source":["model"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["LSTM(\n","  (rnn): LSTM(5, 96, num_layers=4, batch_first=True, bidirectional=True)\n","  (layers): Sequential(\n","    (0): ReLU()\n","    (1): Linear(in_features=192, out_features=96, bias=True)\n","  )\n",")"]},"metadata":{"tags":[]},"execution_count":97}]},{"cell_type":"code","metadata":{"id":"CyYOiGNstXIS"},"source":["# 손실함수\r\n","# Quantile 별로 구해야하니까, q 값에 quantile을 넣어야한다.\r\n","\r\n","def tilted_loss(q,y,f):\r\n","    e = (y-f)\r\n","    return torch.mean(torch.max(q*e, (q-1)*e), axis=-1)\r\n","\r\n","# loss & optimizer setting\r\n","# 원래 critertion이 설정된 손실함수 이지만, quantile 값을 구해야 하므로 대신 위에 새로 정의한 손실함수 사용\r\n","criterion = nn.CrossEntropyLoss()\r\n","optimizer = optim.Adam(model.parameters())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":374},"id":"-S1kfCi3tLRI","executionInfo":{"status":"error","timestamp":1608995738667,"user_tz":-540,"elapsed":3144,"user":{"displayName":"‍최명진(학부학생/사회과학대학 사회복지학과)","photoUrl":"","userId":"07688453603143010105"}},"outputId":"7c648b28-dc97-443b-bca0-a37ba956f874"},"source":["# start training\r\n","for i in range(epoch):\r\n","    for i, (train, train_target) in enumerate(train_set):\r\n","      train = train.float()\r\n","      train_target = train_target.float()\r\n","\r\n","      model.train()\r\n","      outputs = model(train)\r\n","      loss = tilted_loss(0.5, outputs[2][1], train_target[2])\r\n","      \r\n","      optimizer.zero_grad()\r\n","\r\n","      loss.backward()\r\n","      optimizer.step()\r\n","      if i%500 == 0:\r\n","          result = outputs.data.numpy().argmax(axis=2)\r\n","          result_str = ''.join([char_set[c] for c in np.squeeze(result)])\r\n","          print(i, \"loss: \", loss.item(), \"\\nprediction: \", result, \"\\ntrue Y: \", y_data, \"\\nprediction str: \", result_str,\"\\n\")"],"execution_count":null,"outputs":[{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-115-915573c28e12>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m       \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m       \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m       \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;36m500\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m                 create_graph=create_graph)\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m     \u001b[0mgrad_tensors_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_tensor_or_tensors_to_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m     \u001b[0mgrad_tensors_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_make_grads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mretain_graph\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36m_make_grads\u001b[0;34m(outputs, grads)\u001b[0m\n\u001b[1;32m     48\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"grad can be implicitly created only for scalar outputs\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m                 \u001b[0mnew_grads\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemory_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreserve_format\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: grad can be implicitly created only for scalar outputs"]}]},{"cell_type":"code","metadata":{"id":"nGzWhepF2KMR"},"source":["for i, (train, train_target) in enumerate(train_set):\r\n","  print(train_target)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":408},"id":"eRyg-WmC2X5Y","executionInfo":{"status":"error","timestamp":1608995841221,"user_tz":-540,"elapsed":7492,"user":{"displayName":"‍최명진(학부학생/사회과학대학 사회복지학과)","photoUrl":"","userId":"07688453603143010105"}},"outputId":"d1224199-d271-46f2-d5a4-08557259306d"},"source":["for i, (train, train_target) in enumerate(train_set):\r\n","  train = train.float()\r\n","  train_target = train_target.float()\r\n","\r\n","  model.train()\r\n","  outputs = model(train)\r\n","  #print(train_target[2])\r\n","  print(outputs[-1].shape)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["torch.Size([336, 96])\n","torch.Size([336, 96])\n"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-119-b7eb08d8bdd6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m   \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m   \u001b[0;31m#print(train_target[2])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-96-4289758d5897>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    580\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m             result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n\u001b[0;32m--> 582\u001b[0;31m                               self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[0m\u001b[1;32m    583\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m             result = _VF.lstm(input, batch_sizes, hx, self._flat_weights, self.bias,\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"markdown","metadata":{"id":"iisJ13y8Avkq"},"source":[""]}]}